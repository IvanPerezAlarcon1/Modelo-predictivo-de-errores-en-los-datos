{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "archivo = r'C:\\Users\\ivan1\\Desktop\\Modelo-predictivo-de-errores-en-los-datos\\hotel_bookings_1.csv' # se demora 2.8 seg en terminar\n",
    "#archivo = r'C:\\Users\\ivan1\\Desktop\\Modelo-predictivo-de-errores-en-los-datos\\hotel_bookings_1.xlsx' # se demora 43.9 seg en terminar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_from_file(archivo): #detecta el tipo de archivo y devuelve un dataframe del archivo ingresado\n",
    "    aux1 , aux2 = os.path.splitext(archivo)\n",
    "    if (aux2) == '.csv':\n",
    "        dataframe = pd.read_csv(archivo)\n",
    "    if (aux2) == '.xlsx':\n",
    "        dataframe = pd.read_excel(archivo)\n",
    "    return dataframe\n",
    "\n",
    "def sep_col_string_and_num(dataframe): #devuelve 2 DATAFRAMES con las columnas tipo numericas y string\n",
    "    df_num = dataframe.select_dtypes(include=['int64','float64','number'])\n",
    "    df_string = dataframe.select_dtypes(exclude=['int64','float64'])\n",
    "    return df_num,df_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = dataframe_from_file(archivo)\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               hotel arrival_date_month meal country market_segment  \\\n",
      "0       Resort Hotel               July   BB     PRT         Direct   \n",
      "1       Resort Hotel               July   BB     PRT         Direct   \n",
      "2       Resort Hotel               July   BB     GBR         Direct   \n",
      "3       Resort Hotel               July   BB     GBR      Corporate   \n",
      "4       Resort Hotel               July   BB     GBR      Online TA   \n",
      "...              ...                ...  ...     ...            ...   \n",
      "119385    City Hotel             August   BB     BEL  Offline TA/TO   \n",
      "119386    City Hotel             August   BB     FRA      Online TA   \n",
      "119387    City Hotel             August   BB     DEU      Online TA   \n",
      "119388    City Hotel             August   BB     GBR      Online TA   \n",
      "119389    City Hotel             August   HB     DEU      Online TA   \n",
      "\n",
      "       distribution_channel reserved_room_type assigned_room_type  \\\n",
      "0                    Direct                  C                  C   \n",
      "1                    Direct                  C                  C   \n",
      "2                    Direct                  A                  C   \n",
      "3                 Corporate                  A                  A   \n",
      "4                     TA/TO                  A                  A   \n",
      "...                     ...                ...                ...   \n",
      "119385                TA/TO                  A                  A   \n",
      "119386                TA/TO                  E                  E   \n",
      "119387                TA/TO                  D                  D   \n",
      "119388                TA/TO                  A                  A   \n",
      "119389                TA/TO                  A                  A   \n",
      "\n",
      "       deposit_type customer_type reservation_status reservation_status_date  \n",
      "0        No Deposit     Transient          Check-Out              2015-07-01  \n",
      "1        No Deposit     Transient          Check-Out              2015-07-01  \n",
      "2        No Deposit     Transient          Check-Out              2015-07-02  \n",
      "3        No Deposit     Transient          Check-Out              2015-07-02  \n",
      "4        No Deposit     Transient          Check-Out              2015-07-03  \n",
      "...             ...           ...                ...                     ...  \n",
      "119385   No Deposit     Transient          Check-Out              2017-09-06  \n",
      "119386   No Deposit     Transient          Check-Out              2017-09-07  \n",
      "119387   No Deposit     Transient          Check-Out              2017-09-07  \n",
      "119388   No Deposit     Transient          Check-Out              2017-09-07  \n",
      "119389   No Deposit     Transient          Check-Out              2017-09-07  \n",
      "\n",
      "[119390 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "df_col_numericas,df_col_string = sep_col_string_and_num(df)\n",
    "print(df_col_string) #tengo el conjunto de columnas tipo string del conjunto de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888\n",
      "0.8888888888888888\n",
      "0.9166666666666666\n",
      "0.027777777777777776\n",
      "0.037037037037037035\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/luozhouyang/python-string-similarity#n-gram\n",
    "from strsimpy.ngram import NGram\n",
    "\n",
    "twogram = NGram(2)\n",
    "treegram = NGram(3)\n",
    "fourgram = NGram(4)\n",
    "\n",
    "print(twogram.distance('IVAN PEREZ', 'PEREZ ALARCON IVAN'))\n",
    "print(treegram.distance('IVAN PEREZ', 'PEREZ ALARCON IVAN'))\n",
    "print(fourgram.distance('IVAN PEREZ', 'PEREZ ALARCON IVAN'))\n",
    "\n",
    "s1 = 'Adobe CreativeSuite 5 Master Collection from cheap 4zp'\n",
    "s2 = 'Adobe CreativeSuite 5 Master Collection from cheap d1x'\n",
    "print(fourgram.distance(s1, s2))\n",
    "print(treegram.distance(s1,s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41602514716892186\n",
      "0.6249999999999999\n",
      "0.07905694150420949\n"
     ]
    }
   ],
   "source": [
    "from strsimpy.cosine import Cosine\n",
    "\n",
    "cosine = Cosine(3)\n",
    "s_0 = 'My first string'\n",
    "s_1 = 'My other string...'\n",
    "\n",
    "s1 = 'Ivan perez'#'Adobe CreativeSuite 5 Master Collection from cheap 4zp'\n",
    "s2 = 'perez Ivan'#'Adobe CreativeSuite 5 Master Collection from cheap d1x'\n",
    "\n",
    "s3 = 'Ivan perez universidad tecnologica metropolitana'#'Adobe CreativeSuite 5 Master Collection from cheap 4zp'\n",
    "s4 = 'Iván Pérez'#'Adobe CreativeSuite 5 Master Collection from cheap d1x'\n",
    "\n",
    "p0 = cosine.get_profile(s_0)\n",
    "p1 = cosine.get_profile(s_1)\n",
    "print(cosine.similarity_profiles(p0, p1))\n",
    "pp0 = cosine.get_profile(s1)\n",
    "pp1 = cosine.get_profile(s2)\n",
    "print(cosine.similarity_profiles(pp0,pp1))\n",
    "pp2 = cosine.get_profile(s3)\n",
    "pp3 = cosine.get_profile(s4)\n",
    "print(cosine.similarity_profiles(pp2,pp3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROBLEMATICAS MENCIONADAS EN MI TESIS\n",
    "\n",
    "#INSERCION:\n",
    "ins = 'oferta'\n",
    "ins_f = 'ofereta'\n",
    "\n",
    "#ELIMINACION:\n",
    "eli = 'grito'\n",
    "eli_f = 'gito'\n",
    "\n",
    "#SUSTITUCION\n",
    "sus = 'ruido'\n",
    "sus_f = 'ruiso'\n",
    "\n",
    "#TRANSPOSICION:\n",
    "tra = 'rodeo'\n",
    "tra_f = 'rodoe'\n",
    "\n",
    "#ERRORES ORTOGRAFICOS:\n",
    "#(similitud de jaro-winkler, metodo optimo para detectar este problema de duplicacion)\n",
    "#(Levenshtein, metodo optimo para detectar este problema de duplicacion)\n",
    "EO = 'Juan Alberto Perez Zuluaga'\n",
    "EO_F = 'Joan Alverto peres Suluaga'\n",
    "\n",
    "#ABREVIATURAS (truncamiento de uno o mas tokens):\n",
    "#(brecha afín)\n",
    "AB = 'Juan Alberto Perez Zuluaga'\n",
    "AB_F = 'Juan A Pérez Z'\n",
    "\n",
    "#TOKENS FALTANTES (Eliminacion de uno o mas tokens):\n",
    "#(Smith-waterman)\n",
    "TF = 'Juan Alberto Perez Zuluaga'\n",
    "TF_F = 'Juan Perez'\n",
    "\n",
    "#PREFIJOS/SUFIJOS SIN VALOR SEMANTICO (Presencia de subcadenas al principio y/o final):\n",
    "#(similitud de smith-waterman, metodo optimo para detectar este problema de duplicacion)\n",
    "#(Soft TF-IDF-para bajos volumenes de datos // Brecha afín - para altos volumenes de datos)\n",
    "PS = 'Juan Alberto Pérez Zuluaga' \n",
    "PS_F = 'PhD Juan Alberto Pérez Zuluaga, U. Tecnológica Metropolitana'\n",
    "\n",
    "#TOKENS EN DESORDEN:\n",
    "#(Tri-grams, usada tambien cuando existen varios tipos de problemas simultáneos)\n",
    "TD = 'Juan Alberto Pérez Zuluaga'\n",
    "TD_F = 'Pérez Zuluaga Juan Alberto'\n",
    "\n",
    "#ESPACIOS EN BLANCO:\n",
    "#(Smith-waterman)\n",
    "EB = 'Juan Alberto Pérez Zuluaga'\n",
    "EB_F = 'JuanAlberto Pérez Zuluaga'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N-GRAMS SE CLASIFICA POR CARACTERES, es decir, considera cada cadena de caracteres como una secuencia \n",
    "ininterrumpida de caracteres. está a la par de distancia de edicion, distancia de brecha afin, \n",
    "similitud de smith-waterman, similitud de jaro\n",
    "- N-GRAMS es más eficiente en la problemática de detectar duplicados donde las cadenas contienen múltiples palabras y se \n",
    "sabe que tienen un orden correcto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CÓDIGOD DE N-GRAMS A IMPLEMENTAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Soy', 'una', 'cadena']\n",
      "['una', 'cadena', 'de']\n",
      "['cadena', 'de', 'ejemplo']\n"
     ]
    }
   ],
   "source": [
    "cadena_1 = \"Soy una cadena de ejemplo\"\n",
    "cadena_2 = 'it was the best of times it was the worst of times '\n",
    "cadena_2_2 = 'it was the best of times it was the worst of times aloha'\n",
    "cadena_3 = 'Ivan Alejandro Pérez Alarcón'\n",
    "cadena_4 = 'Palabra' #En textBlob si le pasamos una palabra,con n=3 no genera ningun n-gram\n",
    "cadena_5 = 'Pérez Alarcón Iván Alejandro'\n",
    "cadena_6 = 'Hola adiós'\n",
    "cadena_7 = 'Esta es una cadena de prueba'\n",
    "cadena_8 = 'Estha ez una cadena de Prueba'\n",
    "blob_1 = TextBlob(cadena_1).ngrams(3)\n",
    "for gram in blob_1:\n",
    "    print(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'was', 'the']\n",
      "['was', 'the', 'best']\n",
      "['the', 'best', 'of']\n",
      "['best', 'of', 'times']\n",
      "['of', 'times', 'it']\n",
      "['times', 'it', 'was']\n",
      "['it', 'was', 'the']\n",
      "['was', 'the', 'worst']\n",
      "['the', 'worst', 'of']\n",
      "['worst', 'of', 'times']\n"
     ]
    }
   ],
   "source": [
    "blob_2 = TextBlob(cadena_2).ngrams(3)\n",
    "for gram in blob_2:\n",
    "    print(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ivan', 'Alejandro', 'Pérez']\n",
      "['Alejandro', 'Pérez', 'Alarcón']\n"
     ]
    }
   ],
   "source": [
    "blob_3 = TextBlob(cadena_3).ngrams(3)\n",
    "for gram in blob_3:\n",
    "    print(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Palabra']\n"
     ]
    }
   ],
   "source": [
    "blob_4 = TextBlob(cadena_4).ngrams(n = 1)\n",
    "for gram in blob_4:\n",
    "    print(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pérez', 'Alarcón', 'Iván']\n",
      "['Alarcón', 'Iván', 'Alejandro']\n"
     ]
    }
   ],
   "source": [
    "blob_5 = TextBlob(cadena_5).ngrams(n = 3)\n",
    "for gram in blob_5:\n",
    "    print(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hola', 'adiós']\n",
      "Hola\n",
      "adiós\n"
     ]
    }
   ],
   "source": [
    "blob_6 = TextBlob(cadena_6).ngrams(n = 2)\n",
    "for gram in blob_6:\n",
    "    print(gram)\n",
    "    for i in gram:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hola']\n",
      "['adiós']\n",
      "[WordList(['Hola']), WordList(['adiós'])]\n"
     ]
    }
   ],
   "source": [
    "blob_6 = TextBlob(cadena_6).ngrams(1)\n",
    "blob_6\n",
    "for gram in blob_6:\n",
    "    print(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'was', 'the']\n",
      "['was', 'the', 'best']\n",
      "['the', 'best', 'of']\n",
      "['best', 'of', 'times']\n",
      "['of', 'times', 'it']\n",
      "['times', 'it', 'was']\n",
      "['it', 'was', 'the']\n",
      "['was', 'the', 'worst']\n",
      "['the', 'worst', 'of']\n",
      "['worst', 'of', 'times']\n",
      "['of', 'times', 'aloha']\n"
     ]
    }
   ],
   "source": [
    "blob_7_l = []\n",
    "blob_7 = TextBlob(cadena_2_2).ngrams(3)\n",
    "blob_7\n",
    "for gram in blob_7:\n",
    "    print(gram)\n",
    "    blob_7_l.append(tuple(gram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 [('it', 'was', 'the'), ('was', 'the', 'best'), ('the', 'best', 'of'), ('best', 'of', 'times'), ('of', 'times', 'it'), ('times', 'it', 'was'), ('it', 'was', 'the'), ('was', 'the', 'worst'), ('the', 'worst', 'of'), ('worst', 'of', 'times'), ('of', 'times', 'aloha')]\n"
     ]
    }
   ],
   "source": [
    "print(len(blob_7_l),blob_7_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los elementos comunes de las cadenas son:  9 \n",
      " {('was', 'the', 'best'), ('best', 'of', 'times'), ('the', 'best', 'of'), ('times', 'it', 'was'), ('was', 'the', 'worst'), ('of', 'times', 'it'), ('it', 'was', 'the'), ('worst', 'of', 'times'), ('the', 'worst', 'of')}\n"
     ]
    }
   ],
   "source": [
    "aux = set(blob_7_l) & set(blob_8_l)\n",
    "print(\"Los elementos comunes de las cadenas son: \",len(aux), \"\\n\", aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORMULA DE AMÓN CON JACCARD:  0.8181818181818182\n",
      "FORMULA DE AMÓN CON OVERLAP:  0.9\n",
      "FORMULA DE AMÓN CON DICE:  0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"FORMULA DE AMÓN CON JACCARD: \", len(aux)/len(blob_7_l))\n",
    "print(\"FORMULA DE AMÓN CON OVERLAP: \", len(aux)/len(blob_8_l))\n",
    "print(\"FORMULA DE AMÓN CON DICE: \", len(aux)/((len(blob_7_l)+len(blob_8_l))/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORMULA DE AMÓN CON JACCARD, segun pag:  0.8181818181818182\n",
      "FORMULA DE AMÓN CON OVERLAP, segun pag:  0.9\n",
      "FORMULA DE AMÓN CON DICE, segun pag:  10.818181818181818\n"
     ]
    }
   ],
   "source": [
    "print(\"FORMULA DE AMÓN CON JACCARD, segun pag: \", len(aux)/len(blob_7_l))\n",
    "print(\"FORMULA DE AMÓN CON OVERLAP, segun pag: \", len(aux)/len(blob_8_l))\n",
    "print(\"FORMULA DE AMÓN CON DICE, segun pag: \", len(aux)/len(blob_7_l)+len(blob_8_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'was', 'the']\n",
      "['was', 'the', 'best']\n",
      "['the', 'best', 'of']\n",
      "['best', 'of', 'times']\n",
      "['of', 'times', 'it']\n",
      "['times', 'it', 'was']\n",
      "['it', 'was', 'the']\n",
      "['was', 'the', 'worst']\n",
      "['the', 'worst', 'of']\n",
      "['worst', 'of', 'times']\n"
     ]
    }
   ],
   "source": [
    "blob_8_l = []\n",
    "blob_8 = TextBlob(cadena_2).ngrams(3)\n",
    "blob_8\n",
    "for gram in blob_8:\n",
    "    print(gram)\n",
    "    blob_8_l.append(tuple(gram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 [('it', 'was', 'the'), ('was', 'the', 'best'), ('the', 'best', 'of'), ('best', 'of', 'times'), ('of', 'times', 'it'), ('times', 'it', 'was'), ('it', 'was', 'the'), ('was', 'the', 'worst'), ('the', 'worst', 'of'), ('worst', 'of', 'times')]\n"
     ]
    }
   ],
   "source": [
    "print(len(blob_8_l),blob_8_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAS MEJORES FUNCIONES DE N-GRAMS HASTA AHORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://financial-engineering.medium.com/justforfunpython-n-gram-to-quantify-similarity-between-sentences-2d61e68a478c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram(sentence, num):\n",
    "    tmp = [] \n",
    "    sent_len = len(sentence) - num +1\n",
    "    for i in range(sent_len):\n",
    "        tmp.append(sentence[i:i+num]) \n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIFERENCIA\n",
      "3-grams:  0.47619047619047616 ['hol', 'ola', 'la ', ' so', 'soy', 'oy ', 'y i', ' iv', 'ivá', 'ván']\n"
     ]
    }
   ],
   "source": [
    "def diff_ngram(sent_a, sent_b, num):\n",
    "    a = ngram(sent_a, num)\n",
    "    b = ngram(sent_b, num) \n",
    "    common = [] \n",
    "    cnt = 0 \n",
    "    for i in a:\n",
    "        for j in b:\n",
    "            if i == j:\n",
    "                cnt += 1\n",
    "                common.append(i)\n",
    "    return cnt/len(a), common\n",
    "\n",
    "print(\"DIFERENCIA\")\n",
    "\n",
    "a2, word2 = diff_ngram(\"hola que tal?, soy iván\",\"hola soy iván\", 3)\n",
    "print(\"3-grams: \", a2,word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
